import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.tree import _tree
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix


def is_categorical(feature, df):
    """
    Check if a feature is categorical based on unique values in the column.
    """
    unique_values = df[feature].nunique()
    return unique_values < 5


def save_rules_to_file(tree, feature_names, df, filename, idx):
    """
    Save rules to a .pl file with s(CASP) compatible syntax.
    """
    doctors = ["'Dr. Smith'", "'Dr. Johnson'", "'Dra. Lee'", "'Dr. Brown'", "'Dra. Taylor'", "'Dra. Davis'"]  # Lista de nombres
    doctor_name = doctors[idx % len(doctors)]  # Seleccionar un nombre basado en el índice

    with open(filename, 'w') as f:
        f.write(f"% Rules generated by tree {idx}\n")
        f.write("% ---------------------------------------------\n\n")
        tree_ = tree.tree_
        feature_name = [feature_names[i] if i != _tree.TREE_UNDEFINED else "undefined"
                        for i in tree_.feature]

        def get_rules(node, depth, conditions):
            """
            Recursively extract rules from the decision tree.
            Handle categorical and numerical variables for s(CASP).
            """
            if tree_.feature[node] != _tree.TREE_UNDEFINED:
                name = feature_name[node]
                threshold = tree_.threshold[node]
                left = tree_.children_left[node]
                right = tree_.children_right[node]

                if is_categorical(name, df):
                    # For categorical variables, use the exact value
                    threshold_int = int(round(threshold, 5))
                    left_rules = get_rules(left, depth + 1,
                                           conditions + [(name, "==", threshold_int)])
                    right_rules = get_rules(right, depth + 1,
                                            conditions + [(name, "==", threshold_int + 1)])
                else:
                    # For numerical variables, use #=< and #> for s(CASP)
                    left_rules = get_rules(left, depth + 1,
                                           conditions + [(name, "#=<", threshold)])
                    right_rules = get_rules(right, depth + 1,
                                            conditions + [(name, "#>", threshold)])
                return left_rules + right_rules

            else:
                # Leaf node
                value = tree_.value[node]
                target_class = 0 if value[0][0] > value[0][1] else 1
                return [(conditions, target_class)]

        # Get all rules
        rules = get_rules(0, 1, [])

        # Write each rule
        for conditions, target_class in rules:
            formatted_conditions = []
            for i, (name, op, threshold) in enumerate(conditions):
                if op == "==":
                    # For categorical variables
                    formatted_conditions.append(f"{name}(Patient,{round(threshold, 5)})")
                else:
                    # For numerical variables
                    formatted_conditions.append(f"{name}(Patient,X{i})")
                    formatted_conditions.append(f"X{i} {op} {round(threshold, 5)}")

            conditions_str = ",\n    ".join(formatted_conditions)

            f.write(f"diagnosis(Patient,{target_class},{doctor_name}) :- \n") # Quiero q aquí me ponga los nombres de los doctores
            f.write(f"    {conditions_str}.\n\n")

        print(f"Number of rules generated: {len(rules)}")


def save_examples_to_prolog(df, percentage=100):
    """
    Save a percentage of dataset examples in Prolog format.

    Parameters:
    - df: DataFrame containing the dataset.
    - filename: Name of the file to save the Prolog examples.
    - percentage: Percentage of the dataset to save (default is 100).
    """
    num_examples = int(len(df) * (percentage / 100))
    sampled_df = df.sample(n=num_examples)#random_state=42

    examples = []
    for idx, row in sampled_df.iterrows():
        patient_id = f"patient{idx}"  # Use the real index from the DataFrame
        for col_name, value in row.items():
            if col_name == "target":
                continue  # Exclude the target column
            if isinstance(value, float) and value.is_integer():
                value = int(value)  # Remove .0 for integer-like floats
            examples.append(f"{col_name}({patient_id}, {value}).")
        examples.append("")  # Separator between patients

    return examples


def merge_examples_and_rules(example_lines, rule_files, output_file, explainability_file, consult_file):
    """
    Merge examples, rules, and explainability into a single Prolog file.

    Parameters:
    - example_lines: List of strings containing Prolog examples.
    - rule_files: List of filenames containing rules.
    - output_file: Name of the final merged Prolog file.
    - explainability_file: Filename of the explainability Prolog file to include.
    """
    with open(output_file, 'w') as f:
        f.write("% Examples, rules, and explainability in Prolog format\n")
        f.write("% ------------------------------------------------------\n\n")

        # Write examples
        f.write("% Examples:\n")
        for line in example_lines:
            f.write(line + "\n")


        # Write rules
        f.write(f"\n% Rules from {rule_files}:\n")
        with open(rule_files, 'r') as rf:
            f.write(rf.read())

        # Add consult
        f.write(f"\n% Consult from {consult_file}:\n")
        with open(consult_file, 'r') as rf:
            f.write(rf.read())

        # Add explainability information
        f.write(f"\n% Explainability information from {explainability_file}:\n")
        with open(explainability_file, 'r') as ef:
            f.write(ef.read())




def merge_rules_and_explainability(rule_files, output_file, explainability_file, consult_file):
    """
    Merge rules, and explainability into a single Prolog file.

    Parameters:
    - rule_files: List of filenames containing rules.
    - output_file: Name of the final merged Prolog file.
    - explainability_file: Filename of the explainability Prolog file to include.
    """
    with open(output_file, 'w') as f:
        f.write("% Examples and explainability in Prolog format\n")
        f.write("% ------------------------------------------------------\n\n")

        # Write rules
        for rule_file in rule_files:
            f.write(f"\n% Rules from {rule_file}:\n")
            with open(rule_file, 'r') as rf:
                f.write(rf.read())

        # Add consult
        f.write(f"\n% Consult from {consult_file}:\n")
        with open(consult_file, 'r') as rf:
            f.write(rf.read())

        # Add explainability information
        f.write(f"\n% Explainability information from {explainability_file}:\n")
        with open(explainability_file, 'r') as ef:
            f.write(ef.read())


# If wanna tryout by itself:
if __name__ == "__main__":
    """
    # Load the dataset
    columns = [
        "age", "sex", "cp", "trestbps", "chol", "fbs", "restecg", "thalach",
        "exang", "oldpeak", "slope", "ca", "thal", "target"
    ]

    df = pd.read_csv("Heart_disease_cleveland_new.csv", header=0, names=columns)

    X = df.drop("target", axis=1)
    y = df["target"]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

    # Train the Random Forest
    random_forest = RandomForestClassifier(n_estimators=6, max_depth=4)
    random_forest.fit(X_train, y_train)

    # Evaluate the Random Forest
    rf_preds = random_forest.predict(X_test)
    print("\nMetrics:")
    print(classification_report(y_test, rf_preds))
    print("Confusion Matrix:")
    print(confusion_matrix(y_test, rf_preds))
    print("Accuracy:", accuracy_score(y_test, rf_preds))

    # Save rules from the trees to .pl files
    rule_files = []
    for idx, tree in enumerate(random_forest.estimators_):
        filename = f"diagnosis_{idx + 1}.pl"
        print(f"\nGenerating rules for tree {idx + 1}...")
        save_rules_to_file(tree, X.columns, df, filename, idx)
        rule_files.append(filename)

    # Save examples in Prolog format
    dataset_examples = save_examples_to_prolog(df, "", percentage=2)

    # Merge examples and rules into a single file
    final_prolog_file = "final_dataset_and_rules_with_explainability.pl"
    explainability_file = "explainability.pl"
    merge_examples_and_rules(dataset_examples, rule_files, final_prolog_file, explainability_file)
    print(f"\nFinal file generated: {final_prolog_file}")
    """

